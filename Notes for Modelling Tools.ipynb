{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow.contrib.eager as tfe\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDataLoad(local=False,market=True,news=True,sample=False):\n",
    "    try:\n",
    "        from kaggle.competitions import twosigmanews\n",
    "\n",
    "        if(not local):\n",
    "            env = twosigmanews.make_env()\n",
    "        (market_df, news_df) = env.get_training_data()\n",
    "\n",
    "        print('Data fetched from kaggle with {} rows of market data and {} rows of news data'.format(market_df.shape, news_df.shape))\n",
    "    except:\n",
    "        filename=['marketdata_sample.csv','news_sample.csv']\n",
    "        if(not sample):\n",
    "            filename=['market_train.csv','news_train.csv']\n",
    "        print('failed to load data from kaggle, loading data from local directory.')\n",
    "        if(market):\n",
    "            market_df=pd.read_csv('./sampleData/'+filename[0])\n",
    "        if(news):\n",
    "            news_df=pd.read_csv('./sampleData/'+filename[1])\n",
    "        print('Train data loaded!')\n",
    "    if(market & (not news)):\n",
    "        return market_df\n",
    "    if(news & (not market)):\n",
    "        return news_df\n",
    "    return (market_df,news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeCut(df,time, replace=True):\n",
    "    '''\n",
    "    df: dataFrame with attribute time in datatime64 format\n",
    "    time: a time in string\n",
    "    return df slice cutting off the time before the time provided\n",
    "    '''\n",
    "    df.time=pd.to_datetime(df.time)\n",
    "    time=pd.Timestamp(time)\n",
    "    df_slice = df[df.time>time]\n",
    "    if replace:\n",
    "        df=df_slice\n",
    "    return df_slice\n",
    "\n",
    "def formatCodeSet(df,field):\n",
    "    '''\n",
    "    df:dataframe\n",
    "    field:field name of the code in the form string in set format\n",
    "    return the field formatted into array\n",
    "    '''\n",
    "    return df[field].str.findall(f\"'([\\w\\./]+)'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for embedding lookups\n",
    "\n",
    "Embedding lookup is a matrix lookup. The parameters input is a matrix where each row is an item. The input is a row index query. Upon execution, a matrix will be constructed according to input row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a63d622c014c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 定义一个未知变量input_ids用于存储索引\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 定义一个已知变量embedding，是一个5*5的对角矩阵\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# embedding = tf.Variable(np.identity(5, dtype=np.int32))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# 定义一个未知变量input_ids用于存储索引\n",
    "input_ids = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "\n",
    "# 定义一个已知变量embedding，是一个5*5的对角矩阵\n",
    "# embedding = tf.Variable(np.identity(5, dtype=np.int32))\n",
    "\n",
    "# 或者随机一个矩阵\n",
    "embedding = np.asarray([[0.1, 0.2, 0.3], [1.1, 1.2, 1.3], [2.1, 2.2, 2.3], [3.1, 3.2, 3.3], [4.1, 4.2, 4.3]])\n",
    "\n",
    "# 根据input_ids中的id，查找embedding中对应的元素\n",
    "input_embedding = tf.nn.embedding_lookup(embedding, input_ids)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(sess.run(input_embedding, feed_dict={input_ids: [1, 2, 3, 0, 3, 2, 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to load data from kaggle, loading data from local directory.\n",
      "Train data loaded!\n"
     ]
    }
   ],
   "source": [
    "market_train_df, news_train_df=trainDataLoad(sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the embedding, we need to include all assets into the universe and at the same time need to take care of assets that are not included in current universe but may appear in the future. First we need to work out how many unique assets to be embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique market assets in the market training data\n",
    "market_assets=market_train_df.assetCode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique assets mentioned in the news training data\n",
    "news_train_df['assetCodes'] = formatCodeSet(news_train_df,'assetCodes')\n",
    "news_assets=np.unique([item for sublist in news_train_df.assetCodes.tolist() for item in sublist])\n",
    "assets=np.unique(np.concatenate((market_assets,news_assets), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of assets found in both datasets 2805\n"
     ]
    }
   ],
   "source": [
    "#Number of assets found in both datasets\n",
    "print('Number of assets found in both datasets',len(np.intersect1d(market_assets,news_assets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of assets mentioned 10609\n"
     ]
    }
   ],
   "source": [
    "#Total number of assets mentioned\n",
    "print('Total number of assets mentioned',len(assets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of assets in the market 2860\n"
     ]
    }
   ],
   "source": [
    "#Total number of assets in the market\n",
    "print('Total number of assets in the market',len(market_assets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of assets in the news 10554\n"
     ]
    }
   ],
   "source": [
    "#Total number of assets in the news\n",
    "print('Total number of assets in the news',len(news_assets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, many of the assets appears on the news but not all of them appears on the market data. Using asset embeddings instead of a fixed asset code should allow the system to discover more the relationship between the assets through news and market signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000030.KS', '0005.HK', '005490.KS', ..., 'ZYNE.OQ', 'ZZ.N',\n",
       "       'ZZC.N'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kin.poon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pivot=market_train_df.pivot(index='time',columns='assetCode',values='returnsClosePrevMktres10').reindex_axis(assets, axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_embedding(df,timeStart,timeEnd,components):\n",
    "    '''\n",
    "    Do the time cutting and calculate the pca. \n",
    "    The index of the dataframe must be datetime\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from sklearn.decomposition import PCA\n",
    "    if(not isinstance(pivot.index, pd.DatetimeIndex)):\n",
    "        df.index = pd.to_datetime(df.index )\n",
    "    T_s=pd.Timestamp(timeStart)\n",
    "    T_e=pd.Timestamp(timeEnd)\n",
    "    df_T=df[T_s:T_e]\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(df_T)\n",
    "    centre=list(df_T.mean())\n",
    "    return pca,centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reset_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c193d79f7d5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_dim=30\n",
    "assets_num=len(assets)\n",
    "embedding_shape=(assets_num,embedded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca,centre=PCA_embedding(pivot,'2013-1-1','2013-12-30',30)\n",
    "embedding_weight_init=np.transpose(pca.components_)\n",
    "embedding_bias_init=np.matmul(centre,embedding_weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10609, 30)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embedding_weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 30 and 10609 for 'MatMul' (op: 'MatMul') with input shapes: [10609,30], [10609,30].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1625\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 30 and 10609 for 'MatMul' (op: 'MatMul') with input shapes: [10609,30], [10609,30].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-d5dd9cf89b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m embedded_code=tf.multiply(\n\u001b[0;32m      9\u001b[0m     tf.add(\n\u001b[1;32m---> 10\u001b[1;33m         tf.matmul(embedding,embedding_W),embedding_b),\n\u001b[0m\u001b[0;32m     11\u001b[0m     tf.add(\n\u001b[0;32m     12\u001b[0m         tf.nn.sigmoid(tf.matmul(embedding,embedding_V),embedding_c))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2051\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2053\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4855\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   4856\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4857\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4858\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4859\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3270\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3271\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3272\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3273\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3274\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1788\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1789\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1790\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 30 and 10609 for 'MatMul' (op: 'MatMul') with input shapes: [10609,30], [10609,30]."
     ]
    }
   ],
   "source": [
    "embedding=tf.get_variable('asset_embedding',shape=embedding_shape,dtype=tf.float64)\n",
    "embedding_W=tf.get_variable('asset_weights',initializer=embedding_weight_init,dtype=tf.float64)\n",
    "embedding_b=tf.get_variable('asset_bias',initializer=embedding_bias_init,dtype=tf.float64)\n",
    "\n",
    "embedding_V=tf.get_variable('asset_gateWeights',initializer=tf.zeros_initializer,shape=(embedded_dim,assets_num),dtype=tf.float64)\n",
    "embedding_c=tf.get_variable('asset_gateBias',initializer=tf.ones_initializer,shape=(embedded_dim,assets_num),dtype=tf.float64)\n",
    "\n",
    "embedded_code=tf.multiply(\n",
    "    tf.add(\n",
    "        tf.matmul(embedding,embedding_W),embedding_b),\n",
    "    tf.add(\n",
    "        tf.nn.sigmoid(tf.matmul(embedding,embedding_V),embedding_c))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.67571185e-03, -9.63768962e-18, -2.37400476e-03, ...,\n",
       "        -7.80981503e-03, -0.00000000e+00,  3.63670640e-02],\n",
       "       [ 2.50574892e-04, -7.06640193e-17,  1.87747514e-03, ...,\n",
       "        -3.58260816e-03,  0.00000000e+00, -2.24981168e-02],\n",
       "       [-2.22077617e-02,  1.71027975e-16, -1.18437865e-04, ...,\n",
       "         2.57458893e-03, -0.00000000e+00,  2.15119324e-02],\n",
       "       ...,\n",
       "       [-8.80399051e-03,  2.76705658e-16, -6.74032219e-03, ...,\n",
       "         1.61098155e-02,  0.00000000e+00, -2.10604387e-02],\n",
       "       [ 8.29686811e-03,  3.85268785e-17,  2.60499307e-02, ...,\n",
       "        -8.70926846e-03, -0.00000000e+00, -3.42163782e-02],\n",
       "       [ 6.54405942e-03, -4.37907164e-18, -9.84918212e-03, ...,\n",
       "         2.30639292e-02, -0.00000000e+00, -5.03609494e-03]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
