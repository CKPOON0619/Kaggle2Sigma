{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee87c2dd2e98b50e1be61fc5ab16b8c8387233a6"
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n#import tensorflow.contrib.eager as tfe\n#tf.enable_eager_execution()",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f81e46409116f86d053736af88585d43a577f810"
      },
      "cell_type": "code",
      "source": "def trainDataLoad(local=False,market=True,news=True,sample=False):\n    try:\n        from kaggle.competitions import twosigmanews\n\n        if(not local):\n            env = twosigmanews.make_env()\n        (market_df, news_df) = env.get_training_data()\n\n        print('Data fetched from kaggle with {} rows of market data and {} rows of news data'.format(market_df.shape, news_df.shape))\n    except:\n        filename=['marketdata_sample.csv','news_sample.csv']\n        if(not sample):\n            filename=['market_train.csv','news_train.csv']\n        print('failed to load data from kaggle, loading data from local directory.')\n        if(market):\n            market_df=pd.read_csv('./sampleData/'+filename[0])\n        if(news):\n            news_df=pd.read_csv('./sampleData/'+filename[1])\n        print('Train data loaded!')\n    if(market & (not news)):\n        return market_df\n    if(news & (not market)):\n        return news_df\n    return (market_df,news_df)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "753f62e1aaa6a1da8c2d6f53c0d512919795a69c"
      },
      "cell_type": "code",
      "source": "def timeCut(df,timeStart,timeEnd, replace=True):\n    '''\n    df: dataFrame with attribute time in datatime64 format\n    time: a time in string\n    return df slice cutting off the time before the time provided\n    '''\n    df.time=pd.to_datetime(df.time)\n    timeStart=pd.Timestamp(timeStart)\n    timeEnd=pd.Timestamp(timeEnd)\n    df_slice = df[(df.time>timeStart) & (df.time<timeEnd)]\n    if replace:\n        df=df_slice\n    return df_slice\n\ndef formatCodeSet(df,field):\n    '''\n    df:dataframe\n    field:field name of the code in the form string in set format\n    return the field formatted into array\n    '''\n    return df[field].str.findall(f\"'([\\w\\./]+)'\")",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c0058cb4d8bf5f0c55ecae21b72195b2d7de9d19"
      },
      "cell_type": "markdown",
      "source": "# Embeddings"
    },
    {
      "metadata": {
        "_uuid": "804edad1652a692bcfb254f98e958d6db54f0cd5"
      },
      "cell_type": "markdown",
      "source": "### Example for embedding lookups\n\nEmbedding lookup is a matrix lookup. The parameters input is a matrix where each row is an item. The input is a row index query. Upon execution, a matrix will be constructed according to input row index."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "39bfb12e00d6eed417841aaa83a755a5def4299d"
      },
      "cell_type": "code",
      "source": "# 定义一个未知变量input_ids用于存储索引\ninput_ids = tf.placeholder(dtype=tf.int32, shape=[None])\n\n# 定义一个已知变量embedding，是一个5*5的对角矩阵\n# embedding = tf.Variable(np.identity(5, dtype=np.int32))\n\n# 或者随机一个矩阵\nembedding = a = np.asarray([[0.1, 0.2, 0.3], [1.1, 1.2, 1.3], [2.1, 2.2, 2.3], [3.1, 3.2, 3.3], [4.1, 4.2, 4.3]])\n\n# 根据input_ids中的id，查找embedding中对应的元素\ninput_embedding = tf.nn.embedding_lookup(embedding, input_ids)\n\nsess = tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())\n\nprint(sess.run(input_embedding, feed_dict={input_ids: [1, 2, 3, 0, 3, 2, 1]}))",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[1.1 1.2 1.3]\n [2.1 2.2 2.3]\n [3.1 3.2 3.3]\n [0.1 0.2 0.3]\n [3.1 3.2 3.3]\n [2.1 2.2 2.3]\n [1.1 1.2 1.3]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c49c6e8c2edee0a2afbdbafc2d40f2c3487f0ad4"
      },
      "cell_type": "code",
      "source": "market_train_df, news_train_df=trainDataLoad(sample=False)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loading the data... This could take a minute.\nDone!\nData fetched from kaggle with (4072956, 16) rows of market data and (9328750, 35) rows of news data\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "fcb62dcd4ff603232518f0af8caf291a7fc336f6"
      },
      "cell_type": "markdown",
      "source": "To apply the embedding, we need to include all assets into the universe and at the same time need to take care of assets that are not included in current universe but may appear in the future. First we need to work out how many unique assets to be embedded."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ff88af786c24d356bca1aea7b94817b9ccde6e5"
      },
      "cell_type": "code",
      "source": "# Getting assets from the data\ndef getUnique(df,prop):\n    return df[prop].unique()\ndef getUniqueFromArrays(df,prop):\n    try:\n        propLists = df.assetCodes.str.findall(f\"'([\\w\\./]+)'\")\n        return np.unique([item for sublist in propLists.tolist() for item in sublist])\n    except:\n        propLists = df[prop]\n        return np.unique([item for sublist in propLists.tolist() for item in sublist])\ndef uniqueConcat(list1,list2):\n    return np.unique(np.concatenate((list1,list2), axis=0))",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1d2b9b2b9b1d9078758271435951a3f1b0fbf32"
      },
      "cell_type": "code",
      "source": "market_assets=getUnique(market_train_df,'assetCode')\nnews_assets=getUniqueFromArrays(news_train_df,'assetCodes')\nassets=uniqueConcat(market_assets,news_assets)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "413dc9e4f3636df5a9e0b4a951d3ce0cb21b221c"
      },
      "cell_type": "code",
      "source": "#Number of assets found in both datasets\nprint('Number of assets found in both datasets',len(np.intersect1d(market_assets,news_assets)))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Number of assets found in both datasets 3663\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "17f131dcdcab9d6b161426897af3d2b116955dfa"
      },
      "cell_type": "code",
      "source": "#Total number of assets mentioned\nprint('Total number of assets mentioned',len(assets))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Total number of assets mentioned 14410\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01c8912ff0f102c4d2bdbc1ece82f5a38a80142c"
      },
      "cell_type": "code",
      "source": "#Total number of assets in the market\nprint('Total number of assets in the market',len(market_assets))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Total number of assets in the market 3780\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6568bf75a00856248ee754d0a13de0421e4edd4"
      },
      "cell_type": "code",
      "source": "#Total number of assets in the news\nprint('Total number of assets in the news',len(news_assets))",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Total number of assets in the news 14293\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c3c41edb6327f3a9f616db1eaa6767b8a0d109b2"
      },
      "cell_type": "markdown",
      "source": "As observed, many of the assets appears on the news but not all of them appears on the market data. Using asset embeddings instead of a fixed asset code should allow the system to discover more the relationship between the assets through news and market signals. The idea is first to initialise the assets in the market with PCA to estimate their similarities. For the rest, simply initialise with random vectors and let the model fix the similarity. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "657686204d83c40af715aad64cecf7cc33f82a62"
      },
      "cell_type": "code",
      "source": "market_train_df.head()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "                       time   ...    universe\n0 2007-02-01 22:00:00+00:00   ...         1.0\n1 2007-02-01 22:00:00+00:00   ...         0.0\n2 2007-02-01 22:00:00+00:00   ...         1.0\n3 2007-02-01 22:00:00+00:00   ...         1.0\n4 2007-02-01 22:00:00+00:00   ...         1.0\n\n[5 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>A.N</td>\n      <td>Agilent Technologies Inc</td>\n      <td>2606900.0</td>\n      <td>32.19</td>\n      <td>32.17</td>\n      <td>0.005938</td>\n      <td>0.005312</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.001860</td>\n      <td>0.000622</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.034672</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>AAI.N</td>\n      <td>AirTran Holdings Inc</td>\n      <td>2051600.0</td>\n      <td>11.12</td>\n      <td>11.08</td>\n      <td>0.004517</td>\n      <td>-0.007168</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.078708</td>\n      <td>-0.088066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.027803</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>AAP.N</td>\n      <td>Advance Auto Parts Inc</td>\n      <td>1164800.0</td>\n      <td>37.51</td>\n      <td>37.99</td>\n      <td>-0.011594</td>\n      <td>0.025648</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.014332</td>\n      <td>0.045405</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.024433</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>AAPL.O</td>\n      <td>Apple Inc</td>\n      <td>23747329.0</td>\n      <td>84.74</td>\n      <td>86.23</td>\n      <td>-0.011548</td>\n      <td>0.016324</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.048613</td>\n      <td>-0.037182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.007425</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>ABB.N</td>\n      <td>ABB Ltd</td>\n      <td>1208600.0</td>\n      <td>18.02</td>\n      <td>18.01</td>\n      <td>0.011791</td>\n      <td>0.025043</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.012929</td>\n      <td>0.020397</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.017994</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "404fd613e12e35eb4318eb2a0633acfe0313bd15"
      },
      "cell_type": "markdown",
      "source": "The data start from 2007-02-01, suppose we take 5 years of data to calculate stock similarity with the market data. We calculate the similarity for assets appeared in this observation period and initialise the rest with a random vector."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b254a6a157040405b1cb0536c732d926dc4c781b"
      },
      "cell_type": "code",
      "source": "embedded_dim=50\ninitStart='2007-02-01 22:00:00+00:00'\ninitEnd='2012-02-01 22:00:00+00:00'",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1efa2f9e70c8386f0374fa91834b36284fb11e95"
      },
      "cell_type": "code",
      "source": "def PCA_embedding(df,timeStart,timeEnd,components):\n    '''\n    Do the time cutting and calculate the pca. \n    The index of the dataframe must be datetime\n    '''\n    import numpy as np\n    from sklearn.decomposition import PCA\n    if(not isinstance(df.index, pd.DatetimeIndex)):\n        df.index = pd.to_datetime(df.index )\n    T_s=pd.Timestamp(timeStart)\n    T_e=pd.Timestamp(timeEnd)\n    df_T=df[T_s:T_e]\n    pca = PCA(n_components=components)\n    pca.fit(df_T)\n    centre=list(df_T.mean())\n    return pca,centre",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9cc3b2d67267be28de1c7492ea9126ab01f4b50"
      },
      "cell_type": "code",
      "source": "tf.reset_default_graph()",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de5bff9cd96131ff9e53a11657f464fc0bbdb4e3"
      },
      "cell_type": "code",
      "source": "def initAssetEmbeddings(market_data,initStart,initEnd,assets,embedded_dim):\n    #Create the pivot view of the market data\n    pivot=timeCut(market_data,initStart,initEnd, replace=False).pivot(index='time',columns='assetCode',values='returnsClosePrevMktres10').fillna(0)\n    \n    #Find out what assets are missing\n    included_assets=list(pivot.columns)\n    other_assets=list(set(assets).difference(set(pivot.columns)))\n    other_assets.sort()\n    other_assets=other_assets+['unknown']\n    assets=included_assets+other_assets\n    \n    #Calculate the PCA with the data to find out similarity between stocks\n    pca,centre=PCA_embedding(pivot,initStart,initEnd,embedded_dim)\n    \n    #Make up the initialisation\n    #For assets within the market intialisation period, apply the pca for similarity estimation\n    inc_assetEmbd_init=np.transpose(pca.components_)\n    \n    #For other assets, apply a random initialisation\n    othr_assetEmbd_init=np.random.rand(len(other_assets),embedded_dim)\n    \n    #Concatenate both to create a complete embedding variable\n    assets_embd_int=np.concatenate((inc_assetEmbd_init,othr_assetEmbd_init))\n    \n    #To create a tensorflow embedding lookup\n    asset_ids = tf.placeholder(dtype=tf.int32, shape=[None])\n    assetEncodings=tf.get_variable('assetEncodings',initializer=assets_embd_int,dtype=tf.float64)\n    assets_embedding = tf.nn.embedding_lookup(assetEncodings, asset_ids)\n    id_lookups={val:idx for idx, val in enumerate(assets)}\n    return assetEncodings,assets_embedding,id_lookups",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "207cb13ddcef6bc2d880b5bec493e412515561fc"
      },
      "cell_type": "code",
      "source": "assetEncodings,assets_embedding,asset_lookups=initAssetEmbeddings(market_train_df,initStart,initEnd,assets,embedded_dim)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c264cf60ed90d1bccc785b8e3f16b30ad67d17a4"
      },
      "cell_type": "markdown",
      "source": "# Transform the input for embedding lookup\nTo enable embedding lookup, we would need to turn the assetCode into asset ids."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d9a29a32047d2277ee6bc85972d522abe5c8bb5"
      },
      "cell_type": "code",
      "source": "def lookUpTransform(valueType,lookup):\n    if(valueType=='str'):\n        def lookupFunc(value):\n            if value in lookup:\n                return lookup[value]\n            else:\n                return lookup['unknown']\n        return lookupFunc\n    if(valueType=='list'):\n        return lambda values:[lookup[v] if v in lookup else lookup['unknown'] for v in values]",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2cc80c0d698e681472ec129dd42c1f5e6d9dec2"
      },
      "cell_type": "code",
      "source": "market_train_df['assetID']=market_train_df.assetCode.apply(lookUpTransform('str',asset_lookups))\nnews_train_df['assetIDs']=news_train_df.assetCodes.str.findall(f\"'([\\w\\./]+)'\").apply(lookUpTransform('list',asset_lookups))",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee8fda0a88964ea70420ae83b57f340690fe5cb5"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}