{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic settings and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e34ef6128dcfff76f57c9b7d456b3f5ec1627a51",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.6)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Kernel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "3b097d479b9d7c8c6c842f208452cbfb0a8df973"
   },
   "source": [
    "\n",
    "from kaggle.competitions import twosigmanews\n",
    "\n",
    "env = twosigmanews.make_env()\n",
    "(market_train_df, news_train_df) = env.get_training_data()\n",
    "\n",
    "news_train_df['subjects'] = news_train_df['subjects'].str.findall(f\"'([\\w\\./]+)'\")\n",
    "news_train_df['audiences'] = news_train_df['audiences'].str.findall(f\"'([\\w\\./]+)'\")\n",
    "news_train_df['assetCodes'] = news_train_df['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")\n",
    "\n",
    "(market_train_df.shape, news_train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_train_df=pd.read_csv('./sampleData/marketdata_sample.csv')\n",
    "market_train_df=pd.read_csv('./sampleData/news_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a14ab84bb84884c6fc2360c89991e137ce443c6"
   },
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "5ea137f942ac9eea666458fa5703445e1df1fe79",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(data, lookback, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=1):\n",
    "    if max_index is None:\n",
    "        max_index = data.shape[0] - 1\n",
    "        \n",
    "    i = min_index + lookback\n",
    "    \n",
    "    while True:\n",
    "        # Select the rows that will be used for the batch\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, size=batch_size)\n",
    "        else:\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += rows.shape[0]\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "                \n",
    "        samples = np.zeros((len(rows),\n",
    "                   lookback // step,\n",
    "                   data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j]][1]\n",
    "            \n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "efe68f0b5c3eaafd7def4815eb96451e6bb9976a"
   },
   "source": [
    "# Learning the Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d980ff39c1d44b544ce427877bed73676c51fe01"
   },
   "source": [
    "Each model is trained on a particular asset. The time series data for that particular asset needs to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03f5cfb992a821a3e53e7aaa4139caf50f776b30",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='val_loss', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fc9313345a93e94a9b5df6f04425e8550276cd4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop, Adagrad\n",
    "\n",
    "lookback = 30 \n",
    "batch_size = 1024\n",
    "steps_per_epoch = 100\n",
    "epochs = 10\n",
    "data_split = 0.8\n",
    "step = 1\n",
    "\n",
    "def generators(market_data_float):\n",
    "    l = market_data_float.shape[0]\n",
    "    train_gen = generator(market_data_float,\n",
    "                          min_index=0,\n",
    "                          max_index=int(data_split * l),\n",
    "                          batch_size=batch_size,\n",
    "                          lookback=lookback,\n",
    "                          step=step)\n",
    "    \n",
    "    val_gen = generator(market_data_float,\n",
    "                        min_index=int(data_split * l),\n",
    "                        max_index=None,\n",
    "                        batch_size=batch_size,\n",
    "                        lookback=lookback,\n",
    "                        step=step)\n",
    "    \n",
    "    return (train_gen, val_gen)\n",
    "\n",
    "def learn_model(market_data_float):\n",
    "    (train_gen, val_gen) = generators(market_data_float)\n",
    "    input_shape = (None, market_data_float.shape[-1])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.GRU(4, input_shape=input_shape))   \n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer=Adagrad(), loss='mae')\n",
    "    \n",
    "    callbacks = [EarlyStoppingByLossVal(monitor='val_loss', value=0.00001, verbose=1)]\n",
    "    history = model.fit_generator(train_gen,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=10,\n",
    "                                  validation_data=val_gen,\n",
    "                                  validation_steps=100,\n",
    "                                  callbacks=callbacks)\n",
    "    \n",
    "    return (model, history)\n",
    "\n",
    "def learn_models(market_train_df, Histories):\n",
    "    for asset_code, market_data in tqdm(market_train_df.groupby('assetCode')):\n",
    "        # drop the non-numeric columns and handle the nans.\n",
    "        market_float_data = market_data.drop(['assetCode', 'assetName', 'time'], axis=1).fillna(0)\n",
    "        \n",
    "        # normalize the data\n",
    "        scaler = StandardScaler().fit(market_float_data)\n",
    "        \n",
    "        # learn a model using the normalized data\n",
    "        (model, history) = learn_model(scaler.transform(market_float_data))\n",
    "        \n",
    "        # save the history\n",
    "        Histories[asset_code] = history\n",
    "        yield asset_code, (scaler, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc7064ad2ce5a095983d037b2a5bc603cd7752b2"
   },
   "source": [
    "# Random Sample the Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f148143adef195eab68b76ea083f84bbb7c426e4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "n_random_assets = np.random.choice(market_train_df.assetCode.unique(), n)\n",
    "\n",
    "market_train_sampled_df = market_train_df[market_train_df.assetCode.isin(n_random_assets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9beb8beacfd4fafb2d3dfa2d1df070dc7f95c04a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(fig, ax) = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "market_train_sampled_df.groupby('assetCode').plot(x='time', y='close', ax=ax)\n",
    "\n",
    "ax.legend(n_random_assets)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('close')\n",
    "plt.title('Closing Price of %i random assets' % n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb8d9bf794909134085839b7c841fcbe0d14350e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Histories = {}\n",
    "Models = dict(learn_models(market_train_sampled_df, Histories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8584410369c7f6a541bd2238604bb14cf27a8eea"
   },
   "source": [
    "# Unscaled loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88d1d7e11be1b141fa6a7e41629a0078608e5be2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for asset, history in Histories.items():\n",
    "    (fig, ax) = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1) \n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "\n",
    "    plt.title(asset)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
